{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Car Brand Detection System\n",
                "This notebook covers the end-to-end process of:\n",
                "1. Data Inspection\n",
                "2. Data Splitting (Train/Val/Test) with **Data Augmentation**\n",
                "3. Model Training (ResNet18) with **Fine-tuning**\n",
                "4. Evaluation & Inference"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader, Subset\n",
                "from torchvision import transforms, models\n",
                "import torchvision\n",
                "from PIL import Image\n",
                "from collections import Counter\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import torch_directml # Import for AMD GPU support\n",
                "\n",
                "# Configuration\n",
                "DATA_DIR = \"archive\" \n",
                "MODEL_SAVE_PATH = \"car_brand_model.pth\"\n",
                "BEST_MODEL_SAVE_PATH = \"car_brand_model_best.pth\"\n",
                "MAPPING_SAVE_PATH = \"class_mapping.json\"\n",
                "BATCH_SIZE = 32\n",
                "EPOCHS = 10\n",
                "LEARNING_RATE = 0.0001 # Lower learning rate for fine-tuning\n",
                "IMG_SIZE = 224\n",
                "\n",
                "# Set device to AMD GPU via DirectML\n",
                "try:\n",
                "    device = torch_directml.device()\n",
                "    print(f\"Using device: {device} (AMD GPU via DirectML)\")\n",
                "except Exception as e:\n",
                "    print(f\"Error setting DirectML device: {e}. Falling back to CPU.\")\n",
                "    device = torch.device(\"cpu\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_dataset(directory):\n",
                "    data = []\n",
                "    if not os.path.exists(directory):\n",
                "        print(f\"Directory not found: {directory}\")\n",
                "        return\n",
                "\n",
                "    for filename in os.listdir(directory):\n",
                "        if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
                "            parts = filename.split('_')\n",
                "            if len(parts) > 0:\n",
                "                make = parts[0]\n",
                "                data.append(make)\n",
                "    \n",
                "    print(f\"Total images: {len(data)}\")\n",
                "    print(f\"Unique makes: {len(set(data))}\")\n",
                "    \n",
                "    counts = Counter(data)\n",
                "    print(\"\\nTop 20 Makes distribution:\")\n",
                "    \n",
                "    # Visualization\n",
                "    makes, values = zip(*counts.most_common(20))\n",
                "    plt.figure(figsize=(12, 6))\n",
                "    plt.bar(makes, values)\n",
                "    plt.xticks(rotation=45)\n",
                "    plt.title(\"Top 20 Car Brands Distribution\")\n",
                "    plt.show()\n",
                "\n",
                "analyze_dataset(DATA_DIR)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CarDataset(Dataset):\n",
                "    def __init__(self, root_dir, transform=None):\n",
                "        self.root_dir = root_dir\n",
                "        self.transform = transform\n",
                "        self.image_paths = []\n",
                "        self.labels = []\n",
                "        self.classes = set()\n",
                "        \n",
                "        valid_extensions = {'.jpg', '.jpeg', '.png'}\n",
                "        if os.path.exists(root_dir):\n",
                "            for filename in os.listdir(root_dir):\n",
                "                if os.path.splitext(filename)[1].lower() in valid_extensions:\n",
                "                    parts = filename.split('_')\n",
                "                    if len(parts) > 0:\n",
                "                        make = parts[0]\n",
                "                        self.image_paths.append(os.path.join(root_dir, filename))\n",
                "                        self.labels.append(make)\n",
                "                        self.classes.add(make)\n",
                "        \n",
                "        self.classes = sorted(list(self.classes))\n",
                "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
                "        \n",
                "        # print(f\"Found {len(self.image_paths)} images from {len(self.classes)} classes.\")\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.image_paths)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        img_path = self.image_paths[idx]\n",
                "        label_name = self.labels[idx]\n",
                "        label_idx = self.class_to_idx[label_name]\n",
                "        \n",
                "        try:\n",
                "            image = Image.open(img_path).convert('RGB')\n",
                "            if self.transform:\n",
                "                image = self.transform(image)\n",
                "            return image, label_idx\n",
                "        except Exception as e:\n",
                "            print(f\"Error loading image {img_path}: {e}\")\n",
                "            return torch.zeros((3, IMG_SIZE, IMG_SIZE)), label_idx\n",
                "\n",
                "# Transforms with Augmentation for Training\n",
                "train_transform = transforms.Compose([\n",
                "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
                "    transforms.RandomHorizontalFlip(),\n",
                "    transforms.RandomRotation(15),\n",
                "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "val_transform = transforms.Compose([\n",
                "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "# Create base dataset to get classes and length\n",
                "base_dataset = CarDataset(DATA_DIR, transform=None)\n",
                "\n",
                "# Save class mapping\n",
                "with open(MAPPING_SAVE_PATH, 'w') as f:\n",
                "    json.dump(base_dataset.classes, f)\n",
                "print(f\"Saved class mapping to {MAPPING_SAVE_PATH}\")\n",
                "\n",
                "# Manual Split to apply different transforms\n",
                "total_size = len(base_dataset)\n",
                "train_size = int(0.7 * total_size)\n",
                "val_size = int(0.15 * total_size)\n",
                "test_size = total_size - train_size - val_size\n",
                "\n",
                "# Generate random indices\n",
                "indices = torch.randperm(total_size).tolist()\n",
                "train_indices = indices[:train_size]\n",
                "val_indices = indices[train_size:train_size+val_size]\n",
                "test_indices = indices[train_size+val_size:]\n",
                "\n",
                "# Create Subsets with specific transforms\n",
                "# Note: We instantiate CarDataset again for each split to attach the correct transform\n",
                "train_dataset = Subset(CarDataset(DATA_DIR, transform=train_transform), train_indices)\n",
                "val_dataset = Subset(CarDataset(DATA_DIR, transform=val_transform), val_indices)\n",
                "test_dataset = Subset(CarDataset(DATA_DIR, transform=val_transform), test_indices)\n",
                "\n",
                "print(f\"Data Split Summary:\")\n",
                "print(f\"  Training Set:   {len(train_dataset)} images (with Augmentation)\")\n",
                "print(f\"  Validation Set: {len(val_dataset)} images\")\n",
                "print(f\"  Test Set:       {len(test_dataset)} images\")\n",
                "\n",
                "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
                "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
                "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model Setup & Fine-tuning Logic\n",
                "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
                "num_ftrs = model.fc.in_features\n",
                "model.fc = nn.Linear(num_ftrs, len(base_dataset.classes))\n",
                "\n",
                "# Load previous best model if available\n",
                "# FIX: Load to CPU first to avoid DirectML map_location issues\n",
                "if os.path.exists(BEST_MODEL_SAVE_PATH):\n",
                "    print(f\"Loading existing model weights from {BEST_MODEL_SAVE_PATH}...\")\n",
                "    try:\n",
                "        # Load to CPU first\n",
                "        state_dict = torch.load(BEST_MODEL_SAVE_PATH, map_location=\"cpu\")\n",
                "        model.load_state_dict(state_dict)\n",
                "        print(\"Weights loaded successfully! Continuing training...\")\n",
                "    except Exception as e:\n",
                "        print(f\"Error loading weights: {e}. Starting from scratch.\")\n",
                "else:\n",
                "    print(\"No previous model found. Training from scratch.\")\n",
                "\n",
                "# Now move model to device\n",
                "model = model.to(device)\n",
                "\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
                "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training Loop\n",
                "best_acc = 0.0\n",
                "\n",
                "print(\"Evaluating initial performance...\")\n",
                "model.eval()\n",
                "correct = 0\n",
                "total = 0\n",
                "with torch.no_grad():\n",
                "    for inputs, labels in val_loader:\n",
                "        inputs, labels = inputs.to(device), labels.to(device)\n",
                "        outputs = model(inputs)\n",
                "        _, predicted = torch.max(outputs.data, 1)\n",
                "        total += labels.size(0)\n",
                "        correct += (predicted == labels).sum().item()\n",
                "initial_acc = 100 * correct / total\n",
                "print(f\"Initial Validation Accuracy: {initial_acc:.2f}%\")\n",
                "best_acc = initial_acc\n",
                "\n",
                "train_losses = []\n",
                "val_accuracies = []\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
                "    model.train()\n",
                "    running_loss = 0.0\n",
                "    \n",
                "    for i, (inputs, labels) in enumerate(train_loader):\n",
                "        inputs, labels = inputs.to(device), labels.to(device)\n",
                "\n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(inputs)\n",
                "        loss = criterion(outputs, labels)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "\n",
                "        running_loss += loss.item()\n",
                "        if i % 100 == 0:\n",
                "            print(f\"Batch {i}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
                "    \n",
                "    scheduler.step()\n",
                "    epoch_loss = running_loss / len(train_loader)\n",
                "    train_losses.append(epoch_loss)\n",
                "\n",
                "    # Validation\n",
                "    model.eval()\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    with torch.no_grad():\n",
                "        for inputs, labels in val_loader:\n",
                "            inputs, labels = inputs.to(device), labels.to(device)\n",
                "            outputs = model(inputs)\n",
                "            _, predicted = torch.max(outputs.data, 1)\n",
                "            total += labels.size(0)\n",
                "            correct += (predicted == labels).sum().item()\n",
                "\n",
                "    epoch_acc = 100 * correct / total\n",
                "    val_accuracies.append(epoch_acc)\n",
                "    print(f\"Validation Accuracy: {epoch_acc:.2f}%\")\n",
                "    \n",
                "    if epoch_acc > best_acc:\n",
                "        best_acc = epoch_acc\n",
                "        torch.save(model.state_dict(), BEST_MODEL_SAVE_PATH)\n",
                "        print(f\"New best model saved with accuracy: {best_acc:.2f}%\")\n",
                "\n",
                "# Save Final Model\n",
                "torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
                "print(f\"Final model saved to {MODEL_SAVE_PATH}\")\n",
                "\n",
                "# Plotting\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(train_losses, label='Training Loss')\n",
                "plt.title('Training Loss')\n",
                "plt.legend()\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(val_accuracies, label='Validation Accuracy')\n",
                "plt.title('Validation Accuracy')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Final Evaluation on Test Set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best model\n",
                "# FIX: Load to CPU first\n",
                "model.load_state_dict(torch.load(BEST_MODEL_SAVE_PATH, map_location=\"cpu\"))\n",
                "model = model.to(device)\n",
                "model.eval()\n",
                "\n",
                "correct = 0\n",
                "total = 0\n",
                "with torch.no_grad():\n",
                "    for inputs, labels in test_loader:\n",
                "        inputs, labels = inputs.to(device), labels.to(device)\n",
                "        outputs = model(inputs)\n",
                "        _, predicted = torch.max(outputs.data, 1)\n",
                "        total += labels.size(0)\n",
                "        correct += (predicted == labels).sum().item()\n",
                "\n",
                "print(f\"Final Test Accuracy: {100 * correct / total:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Inference Visualization\n",
                "def imshow(inp, title=None):\n",
                "    \"\"\"Imshow for Tensor.\"\"\"\n",
                "    inp = inp.cpu().numpy().transpose((1, 2, 0)) # Move to CPU for numpy\n",
                "    mean = np.array([0.485, 0.456, 0.406])\n",
                "    std = np.array([0.229, 0.224, 0.225])\n",
                "    inp = std * inp + mean\n",
                "    inp = np.clip(inp, 0, 1)\n",
                "    plt.imshow(inp)\n",
                "    if title is not None:\n",
                "        plt.title(title)\n",
                "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
                "\n",
                "# Get a batch of test data\n",
                "inputs, classes_idx = next(iter(test_loader))\n",
                "\n",
                "# Make a grid from batch\n",
                "out = torchvision.utils.make_grid(inputs[:4])\n",
                "\n",
                "outputs = model(inputs[:4].to(device))\n",
                "_, preds = torch.max(outputs, 1)\n",
                "\n",
                "class_names = base_dataset.classes\n",
                "title = [f\"Pred: {class_names[x]}\" for x in preds]\n",
                "\n",
                "plt.figure(figsize=(15, 5))\n",
                "imshow(out, title=title)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}